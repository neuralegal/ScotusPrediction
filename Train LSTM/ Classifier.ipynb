{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train LSTM Classifier\n",
    "This notebook trains the main DF (KKS.csv) using KFold Cross Validation. Expects an already-trained language model which was trained using Create Language Model.ipynb in this directory. Training happens in separate .py file to conserve GPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries, Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from neuralegal_kfold import *\n",
    "from fastai import *\n",
    "\n",
    "def shuffle_keep_pairs(df):\n",
    "    #This function shuffles the DF but keeps docket pairs together to avoid independence issues. Returns shuffled DF.\n",
    "    #Expects DF with labels column 0, text column 1 and docket column 2.\n",
    "    \n",
    "    droprows = []\n",
    "    #Drops half the rows, puts pet and resp text on the same line so they'll shuffle together\n",
    "    for i, row in df.iterrows():\n",
    "        if i > 0:\n",
    "            curdoc = df.loc[i][2]\n",
    "            lastdoc = df.loc[i-1][2]   \n",
    "\n",
    "            if curdoc == lastdoc:\n",
    "                resplabel = df.loc[i][0]\n",
    "                resptext = df.loc[i][1]\n",
    "                df.at[i-1,3] = int(resplabel) \n",
    "                df.at[i-1,4] = resptext\n",
    "\n",
    "                droprows.append(i)\n",
    "    df = df.drop(df.index[droprows])\n",
    "    df = shuffle(df)\n",
    "    \n",
    "    data = []\n",
    "    #Shuffles the DF, then re-places pet and resp text/labels on separate lines\n",
    "    for i, row in df.iterrows():\n",
    "        petlabel = df.loc[i][0]\n",
    "        pettext = df.loc[i][1]\n",
    "        docket = df.loc[i][2]\n",
    "        data.append([int(petlabel),pettext,docket])\n",
    "        \n",
    "        resplabel = df.loc[i][3]\n",
    "        resptext = df.loc[i][4]\n",
    "        docket = df.loc[i][2]\n",
    "        data.append([int(resplabel),resptext,docket])\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def make_kfold_sets(df):\n",
    "    #Makes K new training and testing dataframes with the respective testing sets removed; calls the above shuffle function\n",
    "\n",
    "    df = shuffle_keep_pairs(df)\n",
    "    chunk = int(len(df)/kfolds) #length of each test set\n",
    "\n",
    "    testingsets = []\n",
    "    trainingsets = []\n",
    "\n",
    "    for indx,testingset in enumerate(range(kfolds)):\n",
    "        testingset = df[chunk*indx:chunk*(indx+1)]\n",
    "        testingsets.append(testingset)\n",
    "\n",
    "    for indx,trainingset in enumerate(range(kfolds)):\n",
    "        trainingset = df.drop(testingsets[indx].index.values)\n",
    "        trainingsets.append(trainingset)\n",
    "\n",
    "    return testingsets, trainingsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 30 #Batch size: \n",
    "kfolds = 10\n",
    "learn_rate = 1e-2 #Starting learn rate\n",
    "dropout = 0.4\n",
    "ident = dropout #Puts identifier on saved filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific location of language model files; these need to be separately generated as they are very large.\n",
    "path = '../models'\n",
    "data_lm = load_data(path, fname='lm.pkl')\n",
    "encoder = f'{path}/lm_enc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Outputs data\n",
    "\n",
    "data = '../Dataframes'\n",
    "dataframe = \"KKS.csv\"\n",
    "\n",
    "df = pd.read_csv(f\"{data}/{dataframe}\", encoding = \"utf-8\")\n",
    "testingsets, trainingsets = make_kfold_sets(df) #Creates 10 training and 10 matching testing sets\n",
    "\n",
    "for k in range(kfolds):\n",
    "    kfold(ident, k,dataframe, path, learn_rate, data_lm, encoder,testingsets[k],trainingsets[k],dropout, bs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Justice Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../Dataframes'\n",
    "justices = [\"Antonin Scalia\",\"John Paul Stevens\",\"Anthony M. Kennedy\",\"David H. Souter\",\"Ruth Bader Ginsburg\",\n",
    "            \"Stephen G. Breyer\", \"John G. Roberts, Jr.\",\"Samuel A. Alito, Jr.\",\"Sonia Sotomayor\",\"Elena Kagan\",\n",
    "            \"Neil Gorsuch\", \"Sandra Day O'Connor\",\"William H. Rehnquist\"]\n",
    "\n",
    "for justice in justices:\n",
    "    dataframe = f\"{justice}_questions.csv\"\n",
    "    \n",
    "    df = pd.read_csv(f\"{data}/{dataframe}\", encoding = \"utf-8\")\n",
    "    testingsets, trainingsets = make_kfold_sets(df)\n",
    "    \n",
    "    for k in range(kfolds):\n",
    "        kfold(ident, k,dataframe, path, learn_rate, data_lm, encoder,testingsets[k],trainingsets[k],dropout, bs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
